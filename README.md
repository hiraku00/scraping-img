# Excel Image Scraper

Excel ファイル内の URL リストからウェブページの主要な画像を効率的に抽出し、Excel シートに画像 URL、処理マーク（ハイフン）、リサイズされた画像を埋め込む Python スクリプトです。

## 機能 (Features)

- **Excel 連携:** `.xlsx` ファイルを読み込み、**固定の列名（"URL", "(work)画像 URL"）** に基づいて処理を行い、結果を**D 列（ハイフン）、"(work)画像 URL" 列（URL とハイパーリンク）、E 列（画像埋め込み）**に書き戻します。
- **既存画像のクリア:** スクリプト実行時に、処理対象シート上の**既存の画像（図形）を全て削除**してから処理を開始します。
- **処理済みマークとリンク:** 処理対象となった行の**D 列に "-" を自動挿入**し、取得した画像 URL を **"(work)画像 URL" 列にハイパーリンク付きで書き込み**ます。
- **高度な画像抽出 (優先度の高い順):**
  1.  **メタタグ:** まず `og:image`, 次に `twitter:image` を探します。
  2.  **サイト固有ロジック:** 特定サイト向けに最適化された方法を試します（例: Mercari の内部データ構造や特定の属性を持つ画像タグ、Amazon の主要画像コンテナ内の画像）。
  3.  **構造化データ:** `JSON-LD` (`application/ld+json`) スキーマ内に定義された画像を探します。
  4.  **汎用フォールバック:** 上記のいずれでも見つからない場合、ページ内の `<img>` タグを走査し、アイコン、広告、小さい画像などを除外しながら、最も主要画像と思われるものを選択します。
- **ハイブリッド取得戦略:**
  - まず高速な `requests` ライブラリで HTML を取得・解析。
  - `requests` で失敗した場合や、JavaScript レンダリングが必要な特定ドメイン（`ebay.com`, `mercari.com` など）に対しては、`Selenium` (ヘッドレス Chrome) を使用して動的にページを取得し、再解析。
- **画像処理と埋め込み:**
  - 抽出した画像 URL から画像をダウンロード。
  - `Pillow` を使用して指定された幅にリサイズ（アスペクト比維持）。
  - `openpyxl` を使用して、リサイズされた画像を直接 Excel シートの**E 列のセル**に埋め込み。
  - 画像サイズに合わせて Excel の行の高さ・列の幅を自動調整。
- **堅牢なエラーハンドリング:** ネットワークエラー、タイムアウト、HTTP エラー、画像処理エラーなどを捕捉し、Excel シートとログに記録。
- **柔軟な設定:** コマンドライン引数により、シート名、埋め込み画像の幅、リクエスト間の待機時間などを指定可能。（**列名は固定化されたため指定不要**）
- **デバッグログ:** 詳細な処理状況やエラー情報をファイル (`scraping_debug.log`) に出力可能 (`--debug` オプション)。

## 前提条件 (Requirements)

- Python 3.7 以上
- Google Chrome ブラウザ
- ChromeDriver (インストールされている Google Chrome と同じバージョン)
  - **通常、Selenium Manager (Selenium 4.6 以降に同梱) が、お使いの Chrome に対応する ChromeDriver を自動的にダウンロード・管理します。特別な準備は不要な場合が多いです。**
  - **もし自動セットアップで問題が発生する場合や、特定のバージョンを手動で管理したい場合は、別途 ChromeDriver をダウンロードし、システムの PATH が通ったディレクトリに配置するか、このスクリプトと同じディレクトリに置いてください。**
- 以下の Python ライブラリ:
  - `requests`
  - `beautifulsoup4`
  - `openpyxl`
  - `Pillow`
  - `selenium` (バージョン 4.6.0 以上を推奨)

## インストール (Installation)

必要な Python ライブラリをインストールします。

```bash
pip install requests beautifulsoup4 openpyxl Pillow selenium
```

## 使い方 (Usage)

```bash
python your_script_name.py <input_excel_file.xlsx> [OPTIONS]
```

**必須引数:**

- `input_excel_file.xlsx`: 処理対象の Excel ファイルパス。 **注意:** このファイルは直接上書きされます。実行前にバックアップを取ることを推奨します。

**必須 Excel 列構成:**

スクリプトを実行する前に、Excel シートの**1 行目**に以下のヘッダー名が**正確に**設定されている必要があります。

- **URL 列:** ヘッダー名が `URL` である列 (処理対象の URL が入力されている)
- **(work)画像 URL 列:** ヘッダー名が `(work)画像URL` である列 (抽出された画像 URL とハイパーリンクが書き込まれる)
- **D 列:** 処理マーク (`-`) が書き込まれる列 (ヘッダー名は任意)
- **E 列:** 画像が埋め込まれる列 (ヘッダー名は任意)

**オプション引数 (Options):**

| 引数            | 説明                                                                  | デフォルト値           |
| --------------- | --------------------------------------------------------------------- | ---------------------- |
| `--sheet_name`  | 処理対象のシート名またはインデックス (0 始まり)                       | `0` (最初のシート)     |
| `--image_width` | 埋め込む画像の幅 (ピクセル)                                           | `100`                  |
| `--sleep`       | 各 URL 処理後の待機時間 (秒)                                          | `1.0`                  |
| `--process_all` | 空の URL が見つかった場合でも処理を続行せず、その時点で中断するフラグ | (指定なし: 続行)       |
| `--debug`       | デバッグログを `scraping_debug.log` ファイルに出力するフラグ          | (指定なし: 出力しない) |

**実行例:**

```bash
# 基本的な実行 (data.xlsxの最初のシートを処理)
python excel_image_scraper.py data.xlsx

# 画像幅を150px、待機時間を0.5秒に設定
python excel_image_scraper.py products.xlsx --image_width 150 --sleep 0.5

# デバッグログを有効にして実行
python excel_image_scraper.py input.xlsx --debug
```

## 動作詳細 (How it Works)

1.  **Excel 読み込み:** `openpyxl` で指定された Excel ファイルとシートを読み込み、ヘッダー行から**固定のヘッダー名（"URL", "(work)画像 URL"）** を持つ列と、**固定の列（D 列、E 列）** のインデックスを取得します。
2.  **既存画像クリア:** シート上の既存画像を全てクリアします。
3.  **URL 処理ループ:** 各行の URL セルを読み取ります。
    a. 処理対象の URL が見つかった場合、まず**D 列に "-" を書き込みます**。
    b. **画像 URL 抽出:**
    i. **Requests 試行:** まず `requests` で URL にアクセスし、HTML コンテンツを取得します。
    ii. **HTML 解析:** `BeautifulSoup` を用いて HTML を解析し、以下の優先順位で画像 URL を探します: - `og:image` メタタグ - `twitter:image` メタタグ - サイト固有の抽出ロジック (Mercari の `__NEXT_DATA__` など) - `application/ld+json` (JSON-LD) 内の画像情報 - サイト固有の `<img>` タグ属性 (Amazon のコンテナ ID など) - 一般的な `<img>` タグ (ただし、アイコン、広告、極端に小さい画像などは除外)
    iii. **Selenium フォールバック:** `requests` でのアクセスに失敗した場合、または対象ドメインが `SELENIUM_ONLY_DOMAINS` リストに含まれる場合、`Selenium` (ヘッドレス Chrome) を起動してページを読み込み、動的に生成された HTML ソースを取得して再度 `BeautifulSoup` で解析します。
    iv. **結果記録:** 見つかった画像 URL を **"(work)画像 URL" 列に、URL 文字列とハイパーリンクの両方** を設定して書き込みます。見つからない場合やエラーが発生した場合は、エラーメッセージを書き込みます。
    c. **画像ダウンロードと埋め込み:**
    i. 画像 URL が見つかった場合、`requests` で画像をダウンロードします。
    ii. `Pillow` で画像データを開き、指定された幅にリサイズします (アスペクト比は維持)。適切な画像フォーマット (JPEG, PNG など) に変換します。
    iii. 処理された画像データを `BytesIO` オブジェクトに格納します。
    iv. `openpyxl` を使用して、`BytesIO` オブジェクトから画像を読み込み、**固定の E 列のセル** に埋め込みます。
    v. 画像のサイズに合わせて、行の高さと列の幅を自動調整します。
    d. **待機:** `--sleep` で指定された時間だけ待機し、次の URL の処理に移ります。
4.  **保存:** 全ての URL の処理が完了したら、変更を元の Excel ファイルに上書き保存します。

## ログ (Logging)

- 通常の実行では、処理の開始、終了、主要な警告やエラーがコンソールに出力されます。
- `--debug` オプションを指定すると、`DEBUG` レベルの詳細なログ（各ステップの実行時間、抽出試行の詳細、Selenium の動作など）が `scraping_debug.log` ファイルに出力されます。これは問題発生時の原因究明に役立ちます。

## 注意点 (Notes / Limitations)

- **ウェブサイトの変更:** ウェブサイトの HTML 構造や JavaScript の実装が変更されると、画像抽出ロジックが正しく機能しなくなる可能性があります。
- **ボット対策:** CAPTCHA や高度なボット検出システムを持つサイトでは、スクリプトによるアクセスがブロックされたり、画像が取得できない場合があります。
- **利用規約:** スクレイピング対象のウェブサイトの利用規約を確認し、規約に違反しないように注意してください。過度なアクセスは避け、`--sleep` オプションで適切な待機時間を設定してください。
- **ChromeDriver のバージョン:**
  - 通常、Selenium Manager が Chrome ブラウザのバージョンに合った ChromeDriver を自動的に準備するため、バージョン不一致の問題は発生しにくいです。
  - **もし手動で ChromeDriver を準備・指定する場合**は、使用している Google Chrome ブラウザのバージョンと**正確に一致するバージョン**を選択してください。バージョンが異なると WebDriver の初期化に失敗する可能性があります。
- **ファイルアクセス:** スクリプトは Excel ファイルに書き込みを行うため、対象ファイルへの書き込み権限が必要です。また、処理中に Excel ファイルを手動で開かないでください。**スクリプトは実行時にシート上の既存画像を全て削除します**ので、ご注意ください。
- **Excel 列構成:** スクリプトは**固定されたヘッダー名("URL", "(work)画像 URL")と列位置(D 列, E 列)** を前提として動作します。これらの列が存在しない、またはヘッダー名が異なる場合、エラーが発生します。
