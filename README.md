# Excel Image Scraper (Excel 画像スクレイパー)

Excel ファイル内の URL リストからウェブページの主要な画像を効率的に抽出し、Excel シートに画像 URL、処理マーク（ハイフン）、リサイズされた画像を埋め込む Python スクリプトです。

## 機能 (Features)

- **Excel 連携:** `.xlsx` ファイルを読み込み、**固定の列名（`URL`, `(work)画像URL`）と固定の列位置（D 列、E 列）**に基づいて処理を行い、結果を**D 列（ハイフン）、`C` 列（画像 URL とハイパーリンク）、E 列（画像埋め込み）**に書き戻します。（**注意: `(work)画像URL` はコード例ではC列に設定されていますが、README内では混乱を避けるため列文字ではなくヘッダー名で言及します。**）
- **既存データのクリア:** スクリプト実行時に、処理対象シート上の**既存の画像と、画像 URL 列、ハイフン列のデータを全てクリア**してから処理を開始します。
- **処理済みマークとリンク:** 処理対象となった行の**D 列に `-` を自動挿入**し、取得した画像 URL を **`(work)画像URL` 列にハイパーリンク付きで書き込み**ます。
- **高度な画像抽出 (優先度の高い順):**
    1. **サイト固有ロジック:** 特定サイト（**買取王国 `okoku.jp`**, **2nd Street `2ndstreet.jp`**, **Mercari `mercari.com`**, **Amazon `amazon.*`** など）向けに最適化された方法を試みます。
    2. **メタタグ:** `og:image`, `twitter:image` を探します。（特定のサイトのロゴは除外）
    3. **構造化データ:** `JSON-LD` (`application/ld+json`) 内の画像を探します。
    4. **汎用フォールバック:** 上記で見つからない場合、ページ内の `<img>` タグを走査し、関連性の低い画像（アイコン、広告、サムネイル等）を除外しながら最適なものを選択します。
- **ハイブリッド取得戦略:**
    - まず高速な `requests` ライブラリで試行。
    - `requests` で失敗した場合や、JavaScript レンダリングが必要な**特定ドメイン**（`SELENIUM_ONLY_DOMAINS` リスト参照）、または**動的コンテンツが疑われる場合**に `Selenium` (ヘッドレス Chrome) を使用して再試行。
- **画像処理と埋め込み:**
    - 抽出した URL から画像をダウンロード（**`Referer` ヘッダーを付与**して制限回避を試行）。
    - `Pillow` を使用して指定幅にリサイズ（アスペクト比維持）。
    - `openpyxl` を使用して画像を Excel シートの**固定の E 列**に埋め込み。
    - 画像サイズに合わせて行の高さ・列の幅を自動調整。
- **堅牢なエラーハンドリング:** ネットワークエラー、タイムアウト、HTTP エラー、画像処理エラーなどを捕捉し、Excel シートとログに記録。
- **設定可能なオプション:** コマンドライン引数でシート指定、画像幅、待機時間、デバッグモードなどを制御可能。
- **コードの構造化:** **ビジネスロジック（サイト固有ルール）と共通基盤（WebDriver、HTTP、画像処理、Excel）を分離し、保守性と拡張性を向上させました。**

## 前提条件 (Requirements)

- Python 3.8 以上 (型ヒントの改善などを考慮)
- Google Chrome ブラウザ
- **(推奨) `pip`:** Python のパッケージインストーラー
- 以下の Python ライブラリ:
    - `requests`
    - `beautifulsoup4`
    - `openpyxl`
    - `Pillow`
    - `selenium` (**バージョン 4.6.0 以上を強く推奨。Selenium Manager が含まれます**)

**ChromeDriver について:**

- **Selenium 4.6 以降では、通常 Selenium Manager が ChromeDriver を自動的に検出・ダウンロード・管理**します。多くの場合、手動でのインストールや PATH 設定は不要です。
- スクリプト実行時に、Selenium が適切なバージョンの ChromeDriver を見つけられない場合は、エラーメッセージが表示されます。その場合は、[ChromeDriver の公式サイト](https://chromedriver.chromium.org/downloads) からお使いの Chrome ブラウザに合ったバージョンをダウンロードし、スクリプトと同じディレクトリに置くか、システムの PATH が通った場所に配置してください。

## インストール (Installation)

```bash
pip install requests beautifulsoup4 openpyxl Pillow selenium
```

## 使い方 (Usage)

```bash
python scraping.py <input_excel_file.xlsx> [OPTIONS]
```

**必須引数:**

- `input_excel_file.xlsx`: 処理対象の Excel ファイルパス。**注意:** このファイルは直接上書きされます (デフォルト設定)。**元のファイルを保護するため、スクリプトは出力時に `<元のファイル名>_output.xlsx` のような別名で保存することを推奨します（コード例参照）。**実行前にバックアップを取ることも強く推奨します。

**必須 Excel 列構成:**

スクリプトを実行する前に、Excel シートの**1 行目**に以下のヘッダー名が**正確に**設定されている必要があります。

- **URL 列:** ヘッダー名が `URL` である列。処理対象の URL を入力します。
- **(work)画像 URL 列:** ヘッダー名が `(work)画像URL` である列。ここに抽出された画像 URL とハイパーリンクが書き込まれます。
- **D 列:** この列に処理マーク (`-`) が書き込まれます。（ヘッダー名は任意ですが、列位置は **D 列固定**です）
- **E 列:** この列に画像が埋め込まれます。（ヘッダー名は任意ですが、列位置は **E 列固定**です）

**オプション引数 (Options):**

| 引数             | 説明                                                                                      | デフォルト値           |
| ---------------- | ----------------------------------------------------------------------------------------- | ---------------------- |
| `--sheet`        | 処理対象のシート名またはインデックス (0 始まり)                                           | `0` (最初のシート)     |
| `--width`        | 埋め込む画像の幅 (ピクセル)                                                               | `100`                  |
| `--sleep`        | 各 URL 処理後の待機時間 (秒)。サーバー負荷軽減のため適切な値を設定してください。           | `1.0`                  |
| `--all`          | **(旧 --process_all)** URL 列が空の行に到達した場合、処理を中断せずに続行するかどうか。    | (指定なし: 空で中断)   |
| `--skip-selenium` | Selenium を使用せずに `requests` のみで処理を試みるフラグ。                             | (指定なし: Selenium使用) |
| `--debug`        | デバッグログを `scraping_debug.log` ファイルに出力するフラグ。                            | (指定なし: 出力しない) |

**実行例:**

```bash
# 基本的な実行 (data.xlsx の最初のシートを処理)
python scraping.py data.xlsx

# 画像幅を150px、待機時間を0.5秒に設定
python scraping.py products.xlsx --width 150 --sleep 0.5

# デバッグログを有効にし、Selenium を使用しない
python scraping.py input.xlsx --debug --skip-selenium

# シート名を指定して実行
python scraping.py mydata.xlsx --sheet "商品リスト"
```

## 動作詳細 (How it Works)

1.  **引数解析とログ設定:** コマンドライン引数を解釈し、ロギングを設定します。
2.  **Excel 読み込み:** 指定された Excel ファイルとシートを `openpyxl` で読み込みます。
3.  **ヘッダー検証:** 1 行目から**固定のヘッダー名（`URL`, `(work)画像URL`）** を持つ列を探し、その列インデックスを取得します。必須ヘッダーが見つからない場合はエラー終了します。
4.  **既存データクリア:** `(work)画像URL` 列、**D 列**、**E 列** の既存データと、シート上の全ての**既存画像**をクリアします。
5.  **WebDriver 準備 (必要な場合):** `--skip-selenium` が指定されていない場合、`WebDriverManager` を使用して Selenium WebDriver (ヘッドレス Chrome) を初期化します。失敗した場合は警告を表示し、Selenium を使用しない処理を試みます。
6.  **URL 処理ループ:** 2 行目から最終行まで処理します。
  a. **URL 取得:** `URL` 列から URL を読み取ります。空の場合は `--all` オプションに従って処理を中断または続行します。無効な形式の場合はエラーを記録してスキップします。
  b. **処理マーク:** 有効な URL があれば、まず**D 列に `-` を書き込みます**。
  c. **画像 URL 抽出 (get_image_url_from_url):**
  i. ドメインが `SELENIUM_ONLY_DOMAINS` に含まれるかチェック。
  ii. 含まれない場合、`requests` でアクセスし HTML を取得。
  iii. 取得した HTML を `parse_html_for_image` で解析（サイト固有ロジック → メタタグ → JSON-LD → フォールバック `<img>` の順）。
  iv. `requests` 失敗時、または `SELENIUM_ONLY_DOMAINS` の場合、Selenium でページを取得し、再度 `parse_html_for_image` で解析。
  v. 結果（画像 URL またはエラーメッセージ）を `(work)画像URL` 列に書き込みます。成功時はハイパーリンクも設定します。
  d. **画像ダウンロードと埋め込み (download_and_prepare_image):**
  i. 画像 URL が取得できた場合、`requests` で画像をダウンロード（`Referer` ヘッダー付与）。
  ii. `Pillow` で画像を開き、リサイズし、適切な形式で `BytesIO` に保存。
  iii. `openpyxl` を使用して `BytesIO` から画像を読み込み、**固定の E 列**に埋め込み。
  iv. 行の高さと E 列の幅を自動調整。
  v. 失敗した場合はエラーメッセージを E 列に書き込みます。
  e. **待機:** `--sleep` で指定された時間待機します。
7.  **WebDriver 終了:** WebDriver を使用した場合、`WebDriverManager` が適切に終了処理を行います。
8.  **保存:** 処理が行われた場合（またはデバッグモード時）、変更内容を Excel ファイルに保存します（**推奨: 別名で保存**）。

## ログ (Logging)

- 通常実行: コンソールに処理の開始/終了、主要な警告/エラーを出力。
- `--debug` オプション: 詳細なログ（各ステップ時間、抽出試行、Selenium 動作、サイト固有ロジック等）を `scraping_debug.log` に出力。問題解決に役立ちます。

## 注意点 (Notes / Limitations)

- **ウェブサイト変更:** サイト構造が変わると画像抽出ロジック（特に**サイト固有部分**）が機能しなくなる可能性があります。定期的な確認と更新が必要です。
- **ボット対策:** CAPTCHA 等があるサイトではアクセスがブロックされる可能性があります。
- **利用規約:** スクレイピング対象サイトの利用規約を遵守してください。`--sleep` で適切な待機時間を設定し、過度なアクセスは避けてください。
- **ChromeDriver:** 通常は Selenium Manager が自動管理しますが、問題発生時は手動での準備が必要になる場合があります。
- **ファイルアクセス:** スクリプト実行中は Excel ファイルを手動で開かないでください。**元のファイルは直接上書きされる可能性があるため、バックアップや別名保存を強く推奨します。**
- **Excel 列構成:** **固定ヘッダー名 (`URL`, `(work)画像URL`) と固定列位置 (D, E 列)** が必須です。これらが正しくないとエラーになります。
