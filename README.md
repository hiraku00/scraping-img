# Excel Image Scraper

Excel ファイル内の URL リストからウェブページの主要な画像を効率的に抽出し、Excel シートに画像 URL、処理マーク（ハイフン）、リサイズされた画像を埋め込む Python スクリプトです。

## 機能 (Features)

- **Excel 連携:** `.xlsx` ファイルを読み込み、**固定の列名（"URL", "(work)画像 URL"）** に基づいて処理を行い、結果を**D 列（ハイフン）、"(work)画像 URL" 列（URL とハイパーリンク）、E 列（画像埋め込み）**に書き戻します。
- **既存画像のクリア:** スクリプト実行時に、処理対象シート上の**既存の画像（図形）を全て削除**してから処理を開始します。
- **処理済みマークとリンク:** 処理対象となった行の**D 列に "-" を自動挿入**し、取得した画像 URL を **"(work)画像 URL" 列にハイパーリンク付きで書き込み**ます。
- **高度な画像抽出 (優先度の高い順):**
  1.  **サイト固有ロジック (Specific Site Logic):** まず、特定のサイト（**買取王国 `okoku.jp`**, **2nd Street `2ndstreet.jp`** など）向けに最適化された方法（特定の HTML 要素 ID やクラスから抽出）を試みます。
  2.  **メタタグ (Meta Tags):** 次に `og:image`, `twitter:image` を探します。（買取王国の場合はサイトロゴを除外）
  3.  **サイト固有データ構造 (Specific Data Structures):** Mercari の内部データ構造 (`__NEXT_DATA__`) などを解析します。
  4.  **構造化データ (Structured Data):** `JSON-LD` (`application/ld+json`) スキーマ内に定義された画像を探します。
  5.  **サイト固有 HTML 構造 (Specific HTML Structures):** Amazon の主要画像コンテナ (`#imgTagWrapperId` など) 内の画像を探します。
  6.  **汎用フォールバック (Generic Fallback):** 上記のいずれでも見つからない場合、ページ内の `<img>` タグを走査し、アイコン、広告、小さい画像、**サムネイル画像 (`_tn.`, `_mn.` など)** を除外しながら、最も主要画像と思われるものを選択します。
- **ハイブリッド取得戦略 (Hybrid Fetching Strategy):**
  - まず高速な `requests` ライブラリで HTML を取得・解析。
  - `requests` で失敗した場合（例: 403 Forbidden）や、JavaScript レンダリングが必要な特定ドメイン（`SELENIUM_ONLY_DOMAINS` リスト内のドメイン: **`ebay.com`**, **`mercari.com`**, **`2ndstreet.jp`** など）に対しては、`Selenium` (ヘッドレス Chrome) を使用して動的にページを取得し、再解析。
- **画像処理と埋め込み (Image Processing & Embedding):**
  - 抽出した画像 URL から画像をダウンロード（**`Referer` ヘッダーを付与**して CDN 等のアクセス制限回避を試行）。
  - `Pillow` を使用して指定された幅にリサイズ（アスペクト比維持）。
  - `openpyxl` を使用して、リサイズされた画像を直接 Excel シートの**E 列のセル**に埋め込み。
  - 画像サイズに合わせて Excel の行の高さ・列の幅を自動調整。
- **堅牢なエラーハンドリング (Robust Error Handling):** ネットワークエラー、タイムアウト、HTTP エラー (4xx, 5xx)、画像処理エラーなどを捕捉し、Excel シートとログに記録。
- **柔軟な設定 (Flexible Configuration):** コマンドライン引数により、シート名、埋め込み画像の幅、リクエスト間の待機時間などを指定可能。（**列名は固定化されたため指定不要**）
- **デバッグログ (Debug Logging):** 詳細な処理状況やエラー情報をファイル (`scraping_debug.log`) に出力可能 (`--debug` オプション)。

## 前提条件 (Requirements)

- Python 3.7 以上
- Google Chrome ブラウザ
- ChromeDriver (インストールされている Google Chrome と同じバージョン)
  - **通常、Selenium Manager (Selenium 4.6 以降に同梱) が、お使いの Chrome に対応する ChromeDriver を自動的にダウンロード・管理します。特別な準備は不要な場合が多いです。**
  - **もし自動セットアップで問題が発生する場合や、特定のバージョンを手動で管理したい場合は、別途 ChromeDriver をダウンロードし、システムの PATH が通ったディレクトリに配置するか、このスクリプトと同じディレクトリに置いてください。**
- 以下の Python ライブラリ:
  - `requests`
  - `beautifulsoup4`
  - `openpyxl`
  - `Pillow`
  - `selenium` (バージョン 4.6.0 以上を推奨)

## インストール (Installation)

必要な Python ライブラリをインストールします。

```bash
pip install requests beautifulsoup4 openpyxl Pillow selenium
```

## 使い方 (Usage)

```bash
python scraping.py <input_excel_file.xlsx> [OPTIONS]
```

**必須引数:**

- `input_excel_file.xlsx`: 処理対象の Excel ファイルパス。 **注意:** このファイルは直接上書きされます。実行前にバックアップを取ることを推奨します。

**必須 Excel 列構成:**

スクリプトを実行する前に、Excel シートの**1 行目**に以下のヘッダー名が**正確に**設定されている必要があります。

- **URL 列:** ヘッダー名が `URL` である列 (処理対象の URL が入力されている)
- **(work)画像 URL 列:** ヘッダー名が `(work)画像URL` である列 (抽出された画像 URL とハイパーリンクが書き込まれる)
- **D 列:** 処理マーク (`-`) が書き込まれる列 (ヘッダー名は任意)
- **E 列:** 画像が埋め込まれる列 (ヘッダー名は任意)

**オプション引数 (Options):**

| 引数            | 説明                                                                  | デフォルト値           |
| --------------- | --------------------------------------------------------------------- | ---------------------- |
| `--sheet_name`  | 処理対象のシート名またはインデックス (0 始まり)                       | `0` (最初のシート)     |
| `--image_width` | 埋め込む画像の幅 (ピクセル)                                           | `100`                  |
| `--sleep`       | 各 URL 処理後の待機時間 (秒)                                          | `1.0`                  |
| `--process_all` | 空の URL が見つかった場合でも処理を続行せず、その時点で中断するフラグ | (指定なし: 続行)       |
| `--debug`       | デバッグログを `scraping_debug.log` ファイルに出力するフラグ          | (指定なし: 出力しない) |

**実行例:**

```bash
# 基本的な実行 (data.xlsxの最初のシートを処理)
python scraping.py data.xlsx

# 画像幅を150px、待機時間を0.5秒に設定
python scraping.py products.xlsx --image_width 150 --sleep 0.5

# デバッグログを有効にして実行
python scraping.py input.xlsx --debug
```

## 動作詳細 (How it Works)

1.  **Excel 読み込み:** `openpyxl` で指定された Excel ファイルとシートを読み込み、ヘッダー行から**固定のヘッダー名（"URL", "(work)画像 URL"）** を持つ列と、**固定の列（D 列、E 列）** のインデックスを取得します。
2.  **既存画像クリア:** シート上の既存画像を全てクリアします。
3.  **URL 処理ループ:** 各行の URL セルを読み取ります。
    a. 処理対象の URL が見つかった場合、まず**D 列に "-" を書き込みます**。
    b. **画像 URL 抽出:**
    i. **Selenium Only Domain チェック:** URL のドメインが `SELENIUM_ONLY_DOMAINS` リスト（`2ndstreet.jp` などを含む）にあるか確認します。
    ii. **Requests 試行 (Selenium Only 以外):** リストに含まれない場合、まず `requests` で URL にアクセスし、HTML コンテンツを取得します。
    iii. **HTML 解析:** `BeautifulSoup` を用いて HTML を解析し、以下の優先順位で画像 URL を探します:
        - サイト固有の抽出ロジック (**買取王国**, **2nd Street** など)
        - `og:image` メタタグ (買取王国のロゴは除外)
        - `twitter:image` メタタグ
        - サイト固有のデータ構造 (Mercari の `__NEXT_DATA__` など)
        - `application/ld+json` (JSON-LD) 内の画像情報
        - サイト固有の `<img>` タグ属性 (Amazon のコンテナ ID など)
        - 一般的な `<img>` タグ (ただし、アイコン、広告、小さい画像、サムネイルなどは除外)
    iv. **Selenium 実行:** `requests` でのアクセスに失敗した場合、または対象ドメインが `SELENIUM_ONLY_DOMAINS` リストに含まれる場合、`Selenium` (ヘッドレス Chrome) を起動してページを読み込み、動的に生成された HTML ソースを取得して再度 `BeautifulSoup` で解析します。
    v. **結果記録:** 見つかった画像 URL を **"(work)画像 URL" 列に、URL 文字列とハイパーリンクの両方** を設定して書き込みます。見つからない場合やエラーが発生した場合は、エラーメッセージを書き込みます。
    c. **画像ダウンロードと埋め込み:**
    i. 画像 URL が見つかった場合、`requests` で画像をダウンロードします。この際、**元のページの URL を `Referer` ヘッダーとして付与**します（CDN のアクセス制限回避のため）。
    ii. `Pillow` で画像データを開き、指定された幅にリサイズします (アスペクト比は維持)。適切な画像フォーマット (JPEG, PNG など) に変換します。
    iii. 処理された画像データを `BytesIO` オブジェクトに格納します。
    iv. `openpyxl` を使用して、`BytesIO` オブジェクトから画像を読み込み、**固定の E 列のセル** に埋め込みます。
    v. 画像のサイズに合わせて、行の高さと列の幅を自動調整します。
    d. **待機:** `--sleep` で指定された時間だけ待機し、次の URL の処理に移ります。
4.  **保存:** 全ての URL の処理が完了したら、変更を元の Excel ファイルに上書き保存します。

## ログ (Logging)

- 通常の実行では、処理の開始、終了、主要な警告やエラーがコンソールに出力されます。
- `--debug` オプションを指定すると、`DEBUG` レベルの詳細なログ（各ステップの実行時間、抽出試行の詳細、Selenium の動作、適用されたサイト固有ロジックなど）が `scraping_debug.log` ファイルに出力されます。これは問題発生時の原因究明に役立ちます。

## 注意点 (Notes / Limitations)

- **ウェブサイトの変更:** ウェブサイトの HTML 構造や JavaScript の実装が変更されると、画像抽出ロジック（特に**サイト固有のロジック**）が正しく機能しなくなる可能性があります。定期的なメンテナンスが必要です。
- **ボット対策:** CAPTCHA や高度なボット検出システムを持つサイトでは、スクリプトによるアクセスがブロックされたり、画像が取得できない場合があります。`SELENIUM_ONLY_DOMAINS` リストへの追加や、より高度な対策が必要になる場合があります。
- **利用規約:** スクレイピング対象のウェブサイトの利用規約を確認し、規約に違反しないように注意してください。過度なアクセスは避け、`--sleep` オプションで適切な待機時間を設定してください。
- **ChromeDriver のバージョン:**
  - 通常、Selenium Manager が Chrome ブラウザのバージョンに合った ChromeDriver を自動的に準備するため、バージョン不一致の問題は発生しにくいです。
  - **もし手動で ChromeDriver を準備・指定する場合**は、使用している Google Chrome ブラウザのバージョンと**正確に一致するバージョン**を選択してください。バージョンが異なると WebDriver の初期化に失敗する可能性があります。
- **ファイルアクセス:** スクリプトは Excel ファイルに書き込みを行うため、対象ファイルへの書き込み権限が必要です。また、処理中に Excel ファイルを手動で開かないでください。**スクリプトは実行時にシート上の既存画像を全て削除します**ので、ご注意ください。
- **Excel 列構成:** スクリプトは**固定されたヘッダー名("URL", "(work)画像 URL")と列位置(D 列, E 列)** を前提として動作します。これらの列が存在しない、またはヘッダー名が異なる場合、エラーが発生します。
