# Excel Image Scraper

Excelファイル内のURLリストからウェブページの主要な画像を効率的に抽出し、Excelに画像URLとリサイズされた画像を埋め込むPythonスクリプトです。

## 機能 (Features)

-   **Excel連携:** `.xlsx` ファイルを読み込み、指定された列のURLに基づいて処理を行い、結果を同じファイルに書き戻します。
-   **高度な画像抽出 (優先度の高い順):**
    1.  **メタタグ:** まず `og:image`, 次に `twitter:image` を探します。
    2.  **サイト固有ロジック:** 特定サイト向けに最適化された方法を試します（例: Mercariの内部データ構造や特定の属性を持つ画像タグ、Amazonの主要画像コンテナ内の画像）。
    3.  **構造化データ:** `JSON-LD` (`application/ld+json`) スキーマ内に定義された画像を探します。
    4.  **汎用フォールバック:** 上記のいずれでも見つからない場合、ページ内の `<img>` タグを走査し、アイコン、広告、小さい画像などを除外しながら、最も主要画像と思われるものを選択します。
-   **ハイブリッド取得戦略:**
    -   まず高速な `requests` ライブラリでHTMLを取得・解析。
    -   `requests` で失敗した場合や、JavaScriptレンダリングが必要な特定ドメイン（`ebay.com`, `mercari.com` など）に対しては、`Selenium` (ヘッドレスChrome) を使用して動的にページを取得し、再解析。
-   **画像処理と埋め込み:**
    -   抽出した画像URLから画像をダウンロード。
    -   `Pillow` を使用して指定された幅にリサイズ（アスペクト比維持）。
    -   `openpyxl` を使用して、リサイズされた画像を直接Excelシートのセルに埋め込み。
    -   画像サイズに合わせてExcelの行の高さ・列の幅を自動調整。
-   **堅牢なエラーハンドリング:** ネットワークエラー、タイムアウト、HTTPエラー、画像処理エラーなどを捕捉し、Excelシートとログに記録。
-   **柔軟な設定:** コマンドライン引数により、対象列名、シート名、埋め込み画像の幅、リクエスト間の待機時間などを指定可能。
-   **デバッグログ:** 詳細な処理状況やエラー情報をファイル (`scraping_debug.log`) に出力可能 (`--debug` オプション)。

## 前提条件 (Requirements)

-   Python 3.7 以上
-   Google Chrome ブラウザ
-   ChromeDriver (インストールされているGoogle Chromeと同じバージョン)
    -   **通常、Selenium Manager (Selenium 4.6以降に同梱) が、お使いのChromeに対応するChromeDriverを自動的にダウンロード・管理します。特別な準備は不要な場合が多いです。**
    -   **もし自動セットアップで問題が発生する場合や、特定のバージョンを手動で管理したい場合は、別途ChromeDriverをダウンロードし、システムのPATHが通ったディレクトリに配置するか、このスクリプトと同じディレクトリに置いてください。**
-   以下のPythonライブラリ:
    -   `requests`
    -   `beautifulsoup4`
    -   `openpyxl`
    -   `Pillow`
    -   `selenium` (バージョン 4.6.0 以上を推奨)

## インストール (Installation)

必要なPythonライブラリをインストールします。

```bash
pip install requests beautifulsoup4 openpyxl Pillow selenium
```

## 使い方 (Usage)

```bash
python your_script_name.py <input_excel_file.xlsx> [OPTIONS]
```

**必須引数:**

-   `input_excel_file.xlsx`: 処理対象のExcelファイルパス。

**オプション引数 (Options):**

| 引数                      | 説明                                                          | デフォルト値          |
| ------------------------- | ------------------------------------------------------------- | ------------------- |
| `-u`, `--url_column`        | URLが含まれる列のヘッダー名                                       | `URL`               |
| `-i`, `--image_url_column`  | 抽出した画像URLを書き込む列のヘッダー名                           | `(work)画像URL`     |
| `-p`, `--image_embed_column`| 画像を埋め込む列のヘッダー名                                      | `画像`              |
| `--sheet_name`            | 処理対象のシート名またはインデックス (0始まり)                     | `0` (最初のシート)   |
| `--image_width`           | 埋め込む画像の幅 (ピクセル)                                       | `100`               |
| `--sleep`                 | 各URL処理後の待機時間 (秒)                                      | `1.0`               |
| `--process_all`           | 空のURLが見つかった場合でも処理を続行せず、その時点で中断するフラグ | (指定なし: 続行)    |
| `--debug`                 | デバッグログを `scraping_debug.log` ファイルに出力するフラグ   | (指定なし: 出力しない) |

**実行例:**

```bash
# 基本的な実行
python excel_image_scraper.py data.xlsx

# 列名を指定し、画像幅を150px、待機時間を0.5秒に設定
python excel_image_scraper.py products.xlsx -u "商品ページURL" -p "商品画像" --image_width 150 --sleep 0.5

# デバッグログを有効にして実行
python excel_image_scraper.py input.xlsx --debug
```

## 動作詳細 (How it Works)

1.  **Excel読み込み:** `openpyxl` で指定されたExcelファイルとシートを読み込み、ヘッダー行から指定された列（URL, 画像URL出力, 画像埋め込み）のインデックスを取得します。
2.  **URL処理ループ:** 各行のURLセルを読み取ります。
3.  **画像URL抽出:**
    a.  **Requests試行:** まず `requests` でURLにアクセスし、HTMLコンテンツを取得します。
    b.  **HTML解析:** `BeautifulSoup` を用いてHTMLを解析し、以下の優先順位で画像URLを探します:
        -   `og:image` メタタグ
        -   `twitter:image` メタタグ
        -   サイト固有の抽出ロジック (Mercariの `__NEXT_DATA__` など)
        -   `application/ld+json` (JSON-LD) 内の画像情報
        -   サイト固有の `<img>` タグ属性 (AmazonのコンテナIDなど)
        -   一般的な `<img>` タグ (ただし、アイコン、広告、極端に小さい画像などは除外)
    c.  **Seleniumフォールバック:** `requests` でのアクセスに失敗した場合、または対象ドメインが `SELENIUM_ONLY_DOMAINS` リストに含まれる場合、`Selenium` (ヘッドレスChrome) を起動してページを読み込み、動的に生成されたHTMLソースを取得して再度 `BeautifulSoup` で解析します。
    d.  **結果記録:** 見つかった画像URLを指定された列に書き込みます。見つからない場合やエラーが発生した場合は、エラーメッセージを書き込みます。
4.  **画像ダウンロードと埋め込み:**
    a.  画像URLが見つかった場合、`requests` で画像をダウンロードします。
    b.  `Pillow` で画像データを開き、指定された幅にリサイズします (アスペクト比は維持)。適切な画像フォーマット (JPEG, PNGなど) に変換します。
    c.  処理された画像データを `BytesIO` オブジェクトに格納します。
    d.  `openpyxl` を使用して、`BytesIO` オブジェクトから画像を読み込み、指定されたセルに埋め込みます。
    e.  画像のサイズに合わせて、行の高さと列の幅を自動調整します。
5.  **待機:** `--sleep` で指定された時間だけ待機し、次のURLの処理に移ります。
6.  **保存:** 全てのURLの処理が完了したら、変更を元のExcelファイルに上書き保存します。

## ログ (Logging)

-   通常の実行では、処理の開始、終了、主要な警告やエラーがコンソールに出力されます。
-   `--debug` オプションを指定すると、`DEBUG` レベルの詳細なログ（各ステップの実行時間、抽出試行の詳細、Seleniumの動作など）が `scraping_debug.log` ファイルに出力されます。これは問題発生時の原因究明に役立ちます。

## 注意点 (Notes / Limitations)

-   **ウェブサイトの変更:** ウェブサイトのHTML構造やJavaScriptの実装が変更されると、画像抽出ロジックが正しく機能しなくなる可能性があります。
-   **ボット対策:** CAPTCHAや高度なボット検出システムを持つサイトでは、スクリプトによるアクセスがブロックされたり、画像が取得できない場合があります。
-   **利用規約:** スクレイピング対象のウェブサイトの利用規約を確認し、規約に違反しないように注意してください。過度なアクセスは避け、`--sleep` オプションで適切な待機時間を設定してください。
-   **ChromeDriverのバージョン:**
    -   通常、Selenium ManagerがChromeブラウザのバージョンに合ったChromeDriverを自動的に準備するため、バージョン不一致の問題は発生しにくいです。
    -   **もし手動でChromeDriverを準備・指定する場合**は、使用しているGoogle Chromeブラウザのバージョンと**正確に一致するバージョン**を選択してください。バージョンが異なるとWebDriverの初期化に失敗する可能性があります。
-   **ファイルアクセス:** スクリプトはExcelファイルに書き込みを行うため、対象ファイルへの書き込み権限が必要です。また、処理中にExcelファイルを手動で開かないでください。
